{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Covid-fusion Notebook - Download GSOD File List\n",
    "\n",
    "This notebook will focus on initial ETL techniques related to download individual GSOD files, for 2020. \n",
    "\n",
    "## Table of Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be gathering data from NOAA Global Surface Summary of the Day - GSOD. \n",
    "\n",
    "We will be download data from the https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather Station Data\n",
    "\n",
    "Here, I use GSOD_directory.txt (which is just copied from the web directory HTML page at NOAA) and NOAA_GSOD_stations_clean.txt, an additional file that I found on NOAAâ€™s website, which has a list of all of the weather stations in the GSOD database. Based on some earlier versions of this script, I also exclude a few specific stations because they have a lot of missing data or other issues.\n",
    "\n",
    "The station locations is a fixed-width file, which makes reading it very tedious. Nevertheless, we end up with a great plot of all of the GSOD weather stations in the world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 21:18:33,505 INFO 1798106517 <module> Starting Weather GSOD ETL - Reading GSOD Data\n",
      "2024-10-27 21:18:33,506 INFO 1798106517 <module> file exists\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os.path\n",
    "from os import path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "gsod_data_dir = \"../../data/interim/weather/gsod/\"\n",
    "\n",
    "def get_url_paths(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "    return parent\n",
    "\n",
    "def get_gsod_directory_list():\n",
    "    url = 'https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/2020/'\n",
    "    ext = 'csv'\n",
    "    result = get_url_paths(url, ext)\n",
    "    # print(result)\n",
    "    with open(gsod_data_dir, 'w') as fp:\n",
    "        fp.writelines(\"%s\\n\" % url for url in result)\n",
    "    return\n",
    "\n",
    "def gsod_file_exist():\n",
    "    if path.exists(gsod_data_dir):\n",
    "         return True\n",
    "    else:\n",
    "         return False\n",
    "                   \n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(levelname)s %(module)s %(funcName)s %(message)s',\n",
    "#                    handlers=[logging.FileHandler(\"my_log.log\", mode='w'),\n",
    "#                              stream_handler])\n",
    "                    handlers=[stream_handler])\n",
    "        \n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# handler = logging.StreamHandler(sys.stdout)\n",
    "# handler.setFormatter(formatter)\n",
    "\n",
    "log = logging.getLogger()\n",
    "# log.setLevel(logging.DEBUG)\n",
    "# log.addHandler(handler)\n",
    "\n",
    "log.info('Starting Weather GSOD ETL - Reading GSOD Data')\n",
    "\n",
    "if gsod_file_exist() == False:\n",
    "    get_gsod_directory_list()\n",
    "else:\n",
    "    log.info('file exists')\n",
    "\n",
    "# remember to close the handlers\n",
    "for handler in log.handlers:\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the file list of files first. (if file exists, then don't read in, for now), \n",
    "Need to read in each url, and write into mongo database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
