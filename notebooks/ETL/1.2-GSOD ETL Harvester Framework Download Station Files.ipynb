{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSOD ETL Harvester Framework - Downoad Station Data\n",
    "\n",
    "This notebook will focus on initial ETL techniques downloading various data sets, initially starting with weather\n",
    "\n",
    "## Weather Station Data - Global Surface Summary of the Day (GSOD)\n",
    "\n",
    "Here, I use GSOD_directory.txt (which is just copied from the web directory HTML page at NOAA) and NOAA_GSOD_stations_clean.txt, an additional file that I found on NOAAâ€™s website, which has a list of all of the weather stations in the GSOD database. Based on some earlier versions of this script, I also exclude a few specific stations because they have a lot of missing data or other issues.\n",
    "\n",
    "The station locations is a fixed-width file, which makes reading it very tedious. Nevertheless, we end up with a great plot of all of the GSOD weather stations in the world!\n",
    "\n",
    "We will be gathering data from NOAA Global Surface Summary of the Day - GSOD. \n",
    "\n",
    "We will be download data from the https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/2020\n",
    "\n",
    "# Changelog / To-Do  \n",
    "\n",
    " * **2020-06-26**: Setup mongodb, storing some raw gsod records \n",
    " * **2020-06-11**: Initial creation of framework\n",
    " * **2020-06-05**: Initial download of GSOD data file list for 2020\n",
    " * **2020-05-15**: Project started - covid fusion\n",
    "\n",
    "**To-do**\n",
    "\n",
    "* Looking to create a separate gsod library\n",
    "* don't re-download gsod data, if data is in dir (check file list size against dir list size)\n",
    "* print out message every  100, or 500 downloads, also print number of lines in filelist\n",
    "* put a pause in the download (DON\"T DDOS the site)\n",
    "* Ultimately, the goal is to create a gsod_etl_harvester framework\n",
    "* clean up checking for file in path... define one function\n",
    "* check to see if you can clean up and use global varaibles.. \n",
    "\n",
    "## Table of Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-13 17:09:53,752 - INFO - <module> - <ipython-input-5-1719478a5b94> - Weather GSOD ETL - Started\n",
      "2021-04-13 17:09:53,752 - INFO - <module> - <ipython-input-5-1719478a5b94> - Weather GSOD ETL - Started\n",
      "2021-04-13 17:09:53,752 - INFO - <module> - <ipython-input-5-1719478a5b94> - Weather GSOD ETL - Started\n",
      "2021-04-13 17:09:53,752 INFO <ipython-input-5-1719478a5b94> <module> Weather GSOD ETL - Started\n",
      "2021-04-13 17:09:53,754 - INFO - <module> - <ipython-input-5-1719478a5b94> - file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,754 - INFO - <module> - <ipython-input-5-1719478a5b94> - file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,754 - INFO - <module> - <ipython-input-5-1719478a5b94> - file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,754 INFO <ipython-input-5-1719478a5b94> <module> file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,756 - INFO - <module> - <ipython-input-5-1719478a5b94> - station location file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,756 - INFO - <module> - <ipython-input-5-1719478a5b94> - station location file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,756 - INFO - <module> - <ipython-input-5-1719478a5b94> - station location file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,756 INFO <ipython-input-5-1719478a5b94> <module> station location file exists: ../data/interim/weather/gsod/gsod-url-file-list-2020.txt\n",
      "2021-04-13 17:09:53,758 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,758 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,758 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,758 INFO <ipython-input-5-1719478a5b94> are_gsod_files_extracted Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,784 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - filelist count: 12264\n",
      "2021-04-13 17:09:53,784 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - filelist count: 12264\n",
      "2021-04-13 17:09:53,784 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - filelist count: 12264\n",
      "2021-04-13 17:09:53,784 INFO <ipython-input-5-1719478a5b94> are_gsod_files_extracted filelist count: 12264\n",
      "2021-04-13 17:09:53,786 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - dirlist count: 12264\n",
      "2021-04-13 17:09:53,786 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - dirlist count: 12264\n",
      "2021-04-13 17:09:53,786 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - dirlist count: 12264\n",
      "2021-04-13 17:09:53,786 INFO <ipython-input-5-1719478a5b94> are_gsod_files_extracted dirlist count: 12264\n",
      "2021-04-13 17:09:53,788 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,788 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,788 - INFO - are_gsod_files_extracted - <ipython-input-5-1719478a5b94> - Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,788 INFO <ipython-input-5-1719478a5b94> are_gsod_files_extracted Checking if gsod files have been downloaded already\n",
      "2021-04-13 17:09:53,790 - INFO - <module> - <ipython-input-5-1719478a5b94> - gsod files already extracted\n",
      "2021-04-13 17:09:53,790 - INFO - <module> - <ipython-input-5-1719478a5b94> - gsod files already extracted\n",
      "2021-04-13 17:09:53,790 - INFO - <module> - <ipython-input-5-1719478a5b94> - gsod files already extracted\n",
      "2021-04-13 17:09:53,790 INFO <ipython-input-5-1719478a5b94> <module> gsod files already extracted\n",
      "2021-04-13 17:09:53,792 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - Load gsod data from: ../data/interim/weather/gsod/2020 into datastore: covid-fusion-gsod-data\n",
      "2021-04-13 17:09:53,792 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - Load gsod data from: ../data/interim/weather/gsod/2020 into datastore: covid-fusion-gsod-data\n",
      "2021-04-13 17:09:53,792 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - Load gsod data from: ../data/interim/weather/gsod/2020 into datastore: covid-fusion-gsod-data\n",
      "2021-04-13 17:09:53,792 INFO <ipython-input-5-1719478a5b94> store_normalized_gsod_data Load gsod data from: ../data/interim/weather/gsod/2020 into datastore: covid-fusion-gsod-data\n",
      "2021-04-13 17:09:53,804 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - delete_many: True\n",
      "2021-04-13 17:09:53,804 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - delete_many: True\n",
      "2021-04-13 17:09:53,804 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - delete_many: True\n",
      "2021-04-13 17:09:53,804 INFO <ipython-input-5-1719478a5b94> store_normalized_gsod_data delete_many: True\n",
      "2021-04-13 17:09:53,807 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - delete_many: num docs deleted: 2\n",
      "2021-04-13 17:09:53,807 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - delete_many: num docs deleted: 2\n",
      "2021-04-13 17:09:53,807 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - delete_many: num docs deleted: 2\n",
      "2021-04-13 17:09:53,807 INFO <ipython-input-5-1719478a5b94> store_normalized_gsod_data delete_many: num docs deleted: 2\n",
      "2021-04-13 17:09:53,809 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - Finished loading gsod data\n",
      "2021-04-13 17:09:53,809 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - Finished loading gsod data\n",
      "2021-04-13 17:09:53,809 - INFO - store_normalized_gsod_data - <ipython-input-5-1719478a5b94> - Finished loading gsod data\n",
      "2021-04-13 17:09:53,809 INFO <ipython-input-5-1719478a5b94> store_normalized_gsod_data Finished loading gsod data\n",
      "2021-04-13 17:09:53,811 - INFO - <module> - <ipython-input-5-1719478a5b94> - Weather GSOD ETL - Finished\n",
      "2021-04-13 17:09:53,811 - INFO - <module> - <ipython-input-5-1719478a5b94> - Weather GSOD ETL - Finished\n",
      "2021-04-13 17:09:53,811 - INFO - <module> - <ipython-input-5-1719478a5b94> - Weather GSOD ETL - Finished\n",
      "2021-04-13 17:09:53,811 INFO <ipython-input-5-1719478a5b94> <module> Weather GSOD ETL - Finished\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os.path\n",
    "from os import path\n",
    "import logging\n",
    "import sys\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "covid_fusion_year = \"2020\"\n",
    "gsod_noaa_url = \"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/2020/\"\n",
    "gsod_file_ext_type = \"csv\"\n",
    "gsod_data_dir = \"../data/interim/weather/gsod/\"\n",
    "gsod_directory_list_file = \"gsod-url-file-list-2020.txt\"\n",
    "gsod_file_number_from_filelist = 0\n",
    "gsod_file_number_from_dir = 0\n",
    "gsod_mongo_collection_name = \"covid-fusion-gsod-data\"\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def setup_custom_logger(name):\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(funcName)s - %(module)s - %(message)s')\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def initialize_etl_harvester():\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s %(levelname)s %(module)s %(funcName)s %(message)s',\n",
    "#                    handlers=[logging.FileHandler(\"my_log.log\", mode='w'),\n",
    "#                              stream_handler])\n",
    "                        handlers=[stream_handler])\n",
    "        \n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# handler = logging.StreamHandler(sys.stdout)\n",
    "# handler.setFormatter(formatter)\n",
    "\n",
    "    log = logging.getLogger()\n",
    "# log.setLevel(logging.DEBUG)\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def shutdown_etl_harvester():\n",
    "    # remember to close the handlers\n",
    "    for handler in logger.handlers:\n",
    "        handler.close()\n",
    "    \n",
    "########################################################    \n",
    "# This function reads a list of files with a specific extention from a \n",
    "# remote server. \n",
    "#\n",
    "def get_url_paths(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "    return parent\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def get_gsod_directory_filelist(url, ext, pathname):\n",
    "    logger.info('get_gsod_directory_filelist: Extracting gsod file data list from: ' + url + ' file extension: ' + ext)\n",
    "    result = get_url_paths(url, ext)\n",
    "    # print(result)\n",
    "    with open(pathname, 'w') as fp:\n",
    "        fp.writelines(\"%s\\n\" % url for url in result)\n",
    "    return\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def gsod_filelist_exists(pathname):\n",
    "    if path.exists(pathname):\n",
    "         return True\n",
    "    else:\n",
    "         return False\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def get_gsod_directory_filelist(url, ext, pathname):\n",
    "    logger.info('get_gsod_directory_filelist: Extracting gsod station location file from: ' + url + ' file extension: ' + ext)\n",
    "    result = get_url_paths(url, ext)\n",
    "    # print(result)\n",
    "    with open(pathname, 'w') as fp:\n",
    "        fp.writelines(\"%s\\n\" % url for url in result)\n",
    "    return\n",
    "        \n",
    "########################################################    \n",
    "#\n",
    "def gsod_station_location_file_exists(pathname):\n",
    "    if path.exists(pathname):\n",
    "         return True\n",
    "    else:\n",
    "         return False\n",
    "        \n",
    "########################################################    \n",
    "#\n",
    "def count_gsod_files_in_dir(dir):\n",
    "    return len([1 for x in list(os.scandir(dir)) if x.is_file()])\n",
    "        \n",
    "########################################################    \n",
    "#\n",
    "def are_gsod_files_extracted(pathname, gsod_dir):\n",
    "    global gsod_file_number_from_filelist\n",
    "    global gsod_file_number_from_dir\n",
    "\n",
    "    logger.info('Checking if gsod files have been downloaded already')\n",
    "    gsod_file_number_from_filelist = sum(1 for line in open(pathname))\n",
    "    gsod_file_number_from_dir = count_gsod_files_in_dir(gsod_dir)\n",
    "\n",
    "    logger.info('filelist count: %d', gsod_file_number_from_filelist)\n",
    "    logger.info('dirlist count: %d', gsod_file_number_from_dir)\n",
    "\n",
    "    logger.info('Checking if gsod files have been downloaded already')\n",
    "\n",
    "    if gsod_file_number_from_filelist == gsod_file_number_from_dir:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "        \n",
    "########################################################    \n",
    "#\n",
    "def get_gsod_file(gsod_file_url, gsod_dir):\n",
    "    head, gsod_filename = os.path.split(gsod_file_url)\n",
    "    logger.debug('get_gsod_file: Extracting gsod data file: (' + gsod_file_url + ')')\n",
    "    r = requests.get(gsod_file_url)\n",
    "    \n",
    "    if r.status_code != 404:\n",
    "        with open(gsod_dir+'/'+gsod_filename, 'wb') as fp:\n",
    "            fp.write(r.content)\n",
    "        return True\n",
    "    else:\n",
    "        logger.warning('Response 404: Extracting gsod data file: (' + gsod_file_url + ')')\n",
    "        return False\n",
    "        \n",
    "########################################################    \n",
    "#\n",
    "def extract_gsod_files(gsod_filelist_pathname, gsod_dir):\n",
    "    logger.info('Extracting gsod data to dir: ' + gsod_dir)\n",
    "    count = 0\n",
    "    with open(gsod_filelist_pathname) as fp:\n",
    "        for gsod_file_url in fp:\n",
    "            if get_gsod_file(gsod_file_url.strip('\\n'), gsod_dir) == True:\n",
    "                count += 1\n",
    "\n",
    "    logger.info('Extracted file count: %d', count)\n",
    "\n",
    "########################################################    \n",
    "# associated gsod data to county using lat/lon\n",
    "# (use a hash per county, only using one station, or average all station data???)\n",
    "#\n",
    "\n",
    "########################################################    \n",
    "#\n",
    "def store_normalized_gsod_data(gsod_dir, gsod_collection_name):\n",
    "    logger.info('Load gsod data from: ' + gsod_dir +  ' into datastore: ' + gsod_collection_name)\n",
    "    \n",
    "#    mg_client = pymongo.MongoClient('localhost', 27012)\n",
    "    mg_client = pymongo.MongoClient()\n",
    "    mg_db = mg_client['covid_fusion']\n",
    "    collection_name = 'gsod_raw_data'\n",
    "    db_cm = mg_db[collection_name]\n",
    "    \n",
    "    data = pd.read_csv(gsod_dir+\"/00841599999.csv\")\n",
    "    data_json = json.loads(data.to_json(orient='records'))\n",
    "    result = db_cm.delete_many({})\n",
    "    logger.info('delete_many: %s', result.acknowledged)\n",
    "    logger.info('delete_many: num docs deleted: %s', result.deleted_count)    \n",
    "    result = db_cm.insert_many(data_json)\n",
    "#    logger.info('insert: %s', result.acknowledged)\n",
    "#    logger.info('insert: num docs inserted: %s', result.deleted_count)    \n",
    "\n",
    "    logger.info('Finished loading gsod data')\n",
    "    \n",
    "    \n",
    "#    mng_client = pymongo.MongoClient('localhost', 27017)\n",
    "#    mng_db = mng_client['mongodb_name'] // Replace mongo db name\n",
    "#    collection_name = 'collection_name' // Replace mongo db collection name\n",
    "#    db_cm = mng_db[collection_name]\n",
    "#    cdir = os.path.dirname(__file__)\n",
    "#    file_res = os.path.join(cdir, filepath)\n",
    "\n",
    "#    data = pd.read_csv(file_res)\n",
    "#    data_json = json.loads(data.to_json(orient='records'))\n",
    "#    db_cm.remove()\n",
    "#    db_cm.insert(data_json)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "########################################################    \n",
    "#\n",
    "# GSOD ETL Harvester POC\n",
    "#  \n",
    "########################################################\n",
    "logger = setup_custom_logger('GSOD-ETL-Station-Metadata')\n",
    "initialize_etl_harvester()\n",
    "logger.info('Weather GSOD ETL - Started')\n",
    "\n",
    "gsod_filelist_pathname = gsod_data_dir + gsod_directory_list_file\n",
    "\n",
    "# The filelist is extracted from \n",
    "# get file list, if it doesn't exist\n",
    "if gsod_filelist_exists(gsod_pathname) == False:\n",
    "    get_gsod_directory_filelist(gsod_noaa_url, gsod_file_ext_type, gsod_pathname)\n",
    "else:\n",
    "    logger.info('file exists: ' + gsod_pathname)\n",
    "    \n",
    "# get station data location file, if doesn't exist\n",
    "if gsod_station_location_file_exists(gsod_filelist_pathname) == False:\n",
    "    get_gsod_station_location_file(gsod_noaa_url, gsod_file_ext_type, gsod_filelist_pathname)\n",
    "else:\n",
    "    logger.info('station location file exists: ' + gsod_filelist_pathname)\n",
    "\n",
    "# setup to extract the data files\n",
    "gsod_extract_dir = gsod_data_dir + covid_fusion_year\n",
    "\n",
    "# see if files have been extracted\n",
    "if are_gsod_files_extracted(gsod_pathname, gsod_extract_dir) == False:\n",
    "    # extract the files\n",
    "    logger.info('gsod files not extracted filelist count is: %d', gsod_file_number_from_filelist)\n",
    "    # extract_gsod_files(gsod_pathname, gsod_extract_dir)\n",
    "else:\n",
    "    logger.info('gsod files already extracted')\n",
    "    \n",
    "# move file data into mongo to prep for transformation to county lat/lon\n",
    "store_normalized_gsod_data(gsod_extract_dir, gsod_mongo_collection_name)\n",
    "\n",
    "logger.info('Weather GSOD ETL - Finished')\n",
    "\n",
    "shutdown_etl_harvester()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the file list of files first. (if file exists, then don't read in, for now), \n",
    "Need to read in each url, and write into mongo database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
